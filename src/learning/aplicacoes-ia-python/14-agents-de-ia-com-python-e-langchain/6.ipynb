{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Pessoa:\n",
    "    def __init__(self, nome:str, idade: int, peso: float) -> None:\n",
    "        self.nome = nome \n",
    "        self.idade = idade \n",
    "        self.peso = peso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "lucas = Pessoa(\"Lucas de Sousa\", 31, 101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Lucas de Sousa'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lucas\n",
    "lucas.nome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel\n",
    "\n",
    "\n",
    "class pydPessoa(BaseModel):\n",
    "    nome: str\n",
    "    idade: int\n",
    "    peso: float"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pydPessoa(nome='Lucas de sousa', idade=21, peso=101.2)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lucas2 = pydPessoa(nome=\"Lucas de sousa\", idade=21, peso=101.2)\n",
    "lucas2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.pydantic_v1 import BaseModel, Field \n",
    "from typing import Optional \n",
    "from enum import Enum \n",
    "\n",
    "class UnidadeEnum(str, Enum):\n",
    "    celsius = 'celsius'\n",
    "    fahrenheit = 'fahrenheit'\n",
    "    \n",
    "class ObterTemperaturaAtual(BaseModel):\n",
    "    \"\"\"Obtém a temperatura atual de uma determinada localidade\"\"\"\n",
    "    local:str = Field(description=\"O nome da cidade\", examples=[\"São Paulo\", \"Porto Alegre\"])\n",
    "    unidade:Optional[UnidadeEnum]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'ObterTemperaturaAtual',\n",
       " 'description': 'Obtém a temperatura atual de uma determinada localidade',\n",
       " 'parameters': {'type': 'object',\n",
       "  'properties': {'local': {'description': 'O nome da cidade',\n",
       "    'examples': ['São Paulo', 'Porto Alegre'],\n",
       "    'type': 'string'},\n",
       "   'unidade': {'description': 'An enumeration.',\n",
       "    'enum': ['celsius', 'fahrenheit'],\n",
       "    'type': 'string'}},\n",
       "  'required': ['local']}}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.utils.function_calling import convert_to_openai_function \n",
    "\n",
    "tool_temperature = convert_to_openai_function(ObterTemperaturaAtual)\n",
    "tool_temperature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='', additional_kwargs={'function_call': {'arguments': '{\"local\":\"Porto Alegre\"}', 'name': 'ObterTemperaturaAtual'}}, response_metadata={'token_usage': {'completion_tokens': 23, 'prompt_tokens': 105, 'total_tokens': 128}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'finish_reason': 'function_call', 'logprobs': None}, id='run-42010111-144d-4078-9c46-fe7782dcf63f-0', usage_metadata={'input_tokens': 105, 'output_tokens': 23, 'total_tokens': 128})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI \n",
    "\n",
    "chat = ChatOpenAI() \n",
    "\n",
    "res = chat.invoke(\"Qual é a temperatura de Porto Alegre\", functions=[tool_temperature])\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = chat.invoke(\"Olá\", functions=[tool_temperature], function_call={\"name\": \"ObterTemperaturaAtual\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='', additional_kwargs={'function_call': {'arguments': '{\"local\":\"São Paulo\"}', 'name': 'ObterTemperaturaAtual'}}, response_metadata={'token_usage': {'completion_tokens': 7, 'prompt_tokens': 112, 'total_tokens': 119}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-440b22b7-300f-4f89-b6e5-bac11b64997f-0', usage_metadata={'input_tokens': 112, 'output_tokens': 7, 'total_tokens': 119})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import ChatPromptTemplate \n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "\t(\"system\", \"Você é um assistente amigável chamado Issac\"),\n",
    "\t(\"user\", \"{input}\")\n",
    "])\n",
    "\n",
    "chain = prompt | chat.bind(functions=[tool_temperature])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Olá! Como posso te ajudar hoje?', response_metadata={'token_usage': {'completion_tokens': 12, 'prompt_tokens': 111, 'total_tokens': 123}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-39bdd676-8d1b-495e-8d27-49490971c989-0', usage_metadata={'input_tokens': 111, 'output_tokens': 12, 'total_tokens': 123})"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({\"input\": \"Olá\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='', additional_kwargs={'function_call': {'arguments': '{\"local\":\"Minas Gerais\"}', 'name': 'ObterTemperaturaAtual'}}, response_metadata={'token_usage': {'completion_tokens': 22, 'prompt_tokens': 118, 'total_tokens': 140}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'finish_reason': 'function_call', 'logprobs': None}, id='run-6db49ec6-05de-4074-8a0e-e3d126d78032-0', usage_metadata={'input_tokens': 118, 'output_tokens': 22, 'total_tokens': 140})"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({\"input\": \"Qual a temperatura de Minas Gerais?\"})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
