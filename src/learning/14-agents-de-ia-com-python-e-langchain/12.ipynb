{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.utilities.arxiv import ArxivAPIWrapper\n",
    "from langchain.pydantic_v1 import BaseModel, Field \n",
    "from langchain.tools import StructuredTool \n",
    "\n",
    "class ArxivArgs(BaseModel):\n",
    "    query:str = Field(description=\"Query de busca no ArXiv\")\n",
    "    \n",
    "tool_arvix = StructuredTool.from_function(\n",
    "\tfunc=ArxivAPIWrapper(top_k_results=2).run,\n",
    "\targs_schema=ArxivArgs,\n",
    "\tname='arvix',\n",
    "\tdescription=(\n",
    "\t\t\"Uma ferramenta em torno do Arvix.org.\"\n",
    "\t\t\"Útil para quando você precisa responder a perguntas sobre Física, Matemática, \"\n",
    "\t\t\"Ciência da Compotutação,  Biologia Quantitativa, Finanças Quantitativas, Estatística, \"\n",
    "        \"Engenharia Elétrica e Economia utilizando artigos científicos do arxiv.org. \"\n",
    "        \"A entrada deve ser uma consulta de pesquisa em inglês.\"\n",
    "\t),\n",
    "\treturn_direct=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Descricao: Uma ferramenta em torno do Arvix.org.Útil para quando você precisa responder a perguntas sobre Física, Matemática, Ciência da Compotutação,  Biologia Quantitativa, Finanças Quantitativas, Estatística, Engenharia Elétrica e Economia utilizando artigos científicos do arxiv.org. A entrada deve ser uma consulta de pesquisa em inglês.\n",
      "Args: {'query': {'title': 'Query', 'description': 'Query de busca no ArXiv', 'type': 'string'}}\n"
     ]
    }
   ],
   "source": [
    "print(f\"Descricao: {tool_arvix.description}\")\n",
    "print(f\"Args: {tool_arvix.args}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Published: 2024-06-13\\nTitle: Large Language Models as Software Components: A Taxonomy for LLM-Integrated Applications\\nAuthors: Irene Weber\\nSummary: Large Language Models (LLMs) have become widely adopted recently. Research\\nexplores their use both as autonomous agents and as tools for software\\nengineering. LLM-integrated applications, on the other hand, are software\\nsystems that leverage an LLM to perform tasks that would otherwise be\\nimpossible or require significant coding effort. While LLM-integrated\\napplication engineering is emerging as new discipline, its terminology,\\nconcepts and methods need to be established. This study provides a taxonomy for\\nLLM-integrated applications, offering a framework for analyzing and describing\\nthese systems. It also demonstrates various ways to utilize LLMs in\\napplications, as well as options for implementing such integrations.\\n  Following established methods, we analyze a sample of recent LLM-integrated\\napplications to identify relevant dimensions. We evaluate the taxonomy by\\napplying it to additional cases. This review shows that applications integrate\\nLLMs in numerous ways for various purposes. Frequently, they comprise multiple\\nLLM integrations, which we term ``LLM components''. To gain a clear\\nunderstanding of an application's architecture, we examine each LLM component\\nseparately. We identify thirteen dimensions along which to characterize an LLM\\ncomponent, including the LLM skills leveraged, the format of the output, and\\nmore. LLM-integrated applications are described as combinations of their LLM\\ncomponents. We suggest a concise representation using feature vectors for\\nvisualization.\\n  The taxonomy is effective for describing LLM-integrated applications. It can\\ncontribute to theory building in the nascent field of LLM-integrated\\napplication engineering and aid in developing such systems. Researchers and\\npractitioners explore numerous creative ways to leverage LLMs in applications.\\nThough challenges persist, integrating LLMs may revolutionize the way software\\nsystems are built.\\n\\nPublished: 2024-05-30\\nTitle: Parrot: Efficient Serving of LLM-based Applications with Semantic Variable\\nAuthors: Chaofan Lin, Zhenhua Han, Chengruidong Zhang, Yuqing Yang, Fan Yang, Chen Chen, Lili Qiu\\nSummary: The rise of large language models (LLMs) has enabled LLM-based applications\\n(a.k.a. AI agents or co-pilots), a new software paradigm that combines the\\nstrength of LLM and conventional software. Diverse LLM applications from\\ndifferent tenants could design complex workflows using multiple LLM requests to\\naccomplish one task. However, they have to use the over-simplified\\nrequest-level API provided by today's public LLM services, losing essential\\napplication-level information. Public LLM services have to blindly optimize\\nindividual LLM requests, leading to sub-optimal end-to-end performance of LLM\\napplications.\\n  This paper introduces Parrot, an LLM service system that focuses on the\\nend-to-end experience of LLM-based applications. Parrot proposes Semantic\\nVariable, a unified abstraction to expose application-level knowledge to public\\nLLM services. A Semantic Variable annotates an input/output variable in the\\nprompt of a request, and creates the data pipeline when connecting multiple LLM\\nrequests, providing a natural way to program LLM applications. Exposing\\nSemantic Variables to the public LLM service allows it to perform conventional\\ndata flow analysis to uncover the correlation across multiple LLM requests.\\nThis correlation opens a brand-new optimization space for the end-to-end\\nperformance of LLM-based applications. Extensive evaluations demonstrate that\\nParrot can achieve up to an order-of-magnitude improvement for popular and\\npractical use cases of LLM applications.\""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tool_arvix.run({\"query\": \"llm\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Descrição: A Python shell. Use this to execute python commands. Input should be a valid python command. If you want to see the output of a value, you should print it out with `print(...)`.\n",
      "Args: {'query': {'title': 'Query', 'type': 'string'}}\n"
     ]
    }
   ],
   "source": [
    "from langchain_experimental.tools.python.tool import PythonREPLTool\n",
    "tool_repl = PythonREPLTool()\n",
    "print(f\"Descrição: {tool_repl.description}\")\n",
    "print(f\"Args: {tool_repl.args}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Python REPL can execute arbitrary code. Use with caution.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'oi\\n'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tool_repl.run({\"query\":\"print('oi')\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Descrição: A Python shell. Use this to execute python commands. Input should be a valid python command. If you want to see the output of a value, you should print it out with `print(...)`.\n",
      "Args: {'query': {'title': 'Query', 'type': 'string'}}\n"
     ]
    }
   ],
   "source": [
    "from langchain.agents import load_tools \n",
    "\n",
    "tools = load_tools([\"stackexchange\"])\n",
    "tool_stack = tools[0]\n",
    "print(f\"Descrição: {tool_repl.description}\")\n",
    "print(f\"Args: {tool_repl.args}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Question: @roo_validator error when importing langchain.text_splitter Python\\nI have been working through a <span class=\"highlight\">LangChain</span> tutorial and have hit this problem when trying to import <span class=\"highlight\">langchain</span> into python in vscode on macos 13.4.1. &hellip; /<span class=\"highlight\">agents</span>/init.py&quot;, line 2, in \\nfrom langchain.agents.agent import <span class=\"highlight\">Agent</span>\\nFile &quot;/Users/jamesallison/Desktop/Python Apps Temp/LangchainPDF/.venv/lib/python3.8/site-packages/<span class=\"highlight\">langchain</span>/<span class=\"highlight\">agents</span>/agent.py&quot;, line &hellip; \\n\\nQuestion: How to Stream Langchain (Create pandas dataframe agent) with Azurechatgpt results in Flask Api\\nI want to stream my <span class=\"highlight\">langchain</span> implementation as response in Flask api. The streaming is Taking place but while running the api in the postman, i can see the result only after the stream ends. &hellip; I am using pandas dataframe <span class=\"highlight\">agent</span> from <span class=\"highlight\">langchain</span> combined with chatgpt.\\n# Initialize Azure ChatOpenAI\\nllm = AzureChatOpenAI(\\n    azure_deployment=&quot;gpt-4o&quot;,\\n    api_version=&quot;2024-02-15-preview&quot;,\\n    temperature &hellip; \\n\\nQuestion: Langchain sql agent not connecting to databricks unity catalog table\\nI am trying to use the <span class=\"highlight\">Langchain</span> sql <span class=\"highlight\">agent</span> to connect to a table in databricks unity catalog. &hellip; import SQLDatabase\\nfrom <span class=\"highlight\">langchain</span> import OpenAI\\nfrom langchain.chat_models import ChatOpenAI\\nimport os\\nfrom langchain.agents.agent_types import AgentType\\nfrom langchain.chat_models import AzureChatOpenAI &hellip; '"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tool_stack.run({\"query\":\"Langchain Agents\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: copy_file\n",
      "Descrição: Create a copy of a file in a specified location\n",
      "Args: {'source_path': {'title': 'Source Path', 'description': 'Path of the file to copy', 'type': 'string'}, 'destination_path': {'title': 'Destination Path', 'description': 'Path to save the copied file', 'type': 'string'}}\n",
      "\n",
      "Name: file_delete\n",
      "Descrição: Delete a file\n",
      "Args: {'file_path': {'title': 'File Path', 'description': 'Path of the file to delete', 'type': 'string'}}\n",
      "\n",
      "Name: file_search\n",
      "Descrição: Recursively search for files in a subdirectory that match the regex pattern\n",
      "Args: {'dir_path': {'title': 'Dir Path', 'description': 'Subdirectory to search in.', 'default': '.', 'type': 'string'}, 'pattern': {'title': 'Pattern', 'description': 'Unix shell regex, where * matches everything.', 'type': 'string'}}\n",
      "\n",
      "Name: move_file\n",
      "Descrição: Move or rename a file from one location to another\n",
      "Args: {'source_path': {'title': 'Source Path', 'description': 'Path of the file to move', 'type': 'string'}, 'destination_path': {'title': 'Destination Path', 'description': 'New path for the moved file', 'type': 'string'}}\n",
      "\n",
      "Name: read_file\n",
      "Descrição: Read file from disk\n",
      "Args: {'file_path': {'title': 'File Path', 'description': 'name of file', 'type': 'string'}}\n",
      "\n",
      "Name: write_file\n",
      "Descrição: Write file to disk\n",
      "Args: {'file_path': {'title': 'File Path', 'description': 'name of file', 'type': 'string'}, 'text': {'title': 'Text', 'description': 'text to write to file', 'type': 'string'}, 'append': {'title': 'Append', 'description': 'Whether to append to an existing file.', 'default': False, 'type': 'boolean'}}\n",
      "\n",
      "Name: list_directory\n",
      "Descrição: List files and directories in a specified folder\n",
      "Args: {'dir_path': {'title': 'Dir Path', 'description': 'Subdirectory to list.', 'default': '.', 'type': 'string'}}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.agent_toolkits.file_management.toolkit import FileManagementToolkit\n",
    "\n",
    "tool_kit = FileManagementToolkit(\n",
    "\troot_dir=\"files\"\n",
    ")\n",
    "\n",
    "tools = tool_kit.get_tools()\n",
    "\n",
    "for tool in tools:\n",
    "    print(f\"Name: {tool.name}\")\n",
    "    print(f\"Descrição: {tool.description}\")\n",
    "    print(f\"Args: {tool.args}\\n\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.agent_toolkits.file_management.toolkit import FileManagementToolkit\n",
    "\n",
    "tool_kit = FileManagementToolkit(\n",
    "\troot_dir=\"arquivos\",\n",
    "\tselected_tools=[\"write_file\", \"read_file\", \"file_search\", \"list_directory\"]\n",
    ")\n",
    "\n",
    "tools = tool_kit.get_tools()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import ChatPromptTemplate \n",
    "from langchain_openai import ChatOpenAI \n",
    "from langchain_core.utils.function_calling import convert_to_openai_function\n",
    "\n",
    "tools_json = [convert_to_openai_function(tool) for tool in tools]\n",
    "tool_run = {tool.name: tool for tool in tools}\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "\t(\"system\", \"Você é um assistente amigável chamada Isaac capaz de gerencia arquivos\"),\n",
    "\t(\"user\", \"{input}\")\n",
    "])\n",
    "\n",
    "chat = ChatOpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents.agent import AgentFinish\n",
    "\n",
    "def roteamento(resultado):\n",
    "    if isinstance(resultado, AgentFinish):\n",
    "        return resultado.return_values['output']\n",
    "    else:\n",
    "        return tool_run[resultado.tool].run(resultado.tool_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents.output_parsers import OpenAIFunctionsAgentOutputParser\n",
    "\n",
    "chain = prompt | chat.bind(functions=tools_json) | OpenAIFunctionsAgentOutputParser() | roteamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Olá! Eu sou o assistente Isaac e posso te ajudar a gerenciar arquivos. Posso escrever texto em arquivos, ler o conteúdo de arquivos, buscar arquivos com base em padrões de regex e listar arquivos e diretórios em uma pasta específica. Se precisar de ajuda com alguma dessas tarefas, é só me chamar!'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({\"input\": \"O que você é capaz de fazer?\"})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
