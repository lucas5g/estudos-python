{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain_community.chat_message_histories import SQLChatMessageHistory\n",
    "from langchain_groq import ChatGroq\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "from langchain_core.messages import HumanMessage\n",
    "from langchain_openai import ChatOpenAI\n",
    "from sqlalchemy import create_engine\n",
    "from langchain_core.chat_history import BaseChatMessageHistory, InMemoryChatMessageHistory\n",
    "from database import Chat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_model(model: str):\n",
    "    model = model.lower()\n",
    "\n",
    "    if model in (\"llama3-8b-8192\", \"llama-3.1-8b-instant\"):\n",
    "        return ChatGroq(model=model, temperature=0, api_key=os.getenv(\"GROQ_API_KEY\"))\n",
    "\n",
    "    if model in (\"gpt-3.5-turbo\", \"gpt-4o\"):\n",
    "        return ChatOpenAI(\n",
    "            model=model, temperature=0, api_key=os.getenv(\"OPENAI_API_KEY\")\n",
    "        )\n",
    "    return \"Modelo não cadastrado :(\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatGroq(client=<groq.resources.chat.completions.Completions object at 0x7c379957f910>, async_client=<groq.resources.chat.completions.AsyncCompletions object at 0x7c379957e950>, model_name='llama-3.1-8b-instant', temperature=1e-08, groq_api_key=SecretStr('**********'))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = find_model(\"llama-3.1-8b-instant\")\n",
    "\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "InMemoryChatMessageHistory(messages=[])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_session_history(session_id):\n",
    "    \n",
    "    \n",
    "\ttry:\n",
    "\t\tpass\n",
    "\t\treturn Chat.get(Chat.id == session_id).get()\t\n",
    "\texcept:\n",
    "\t\treturn InMemoryChatMessageHistory()\n",
    "\n",
    "\tfinally:\n",
    "\t\tprint(session_id)\n",
    "\n",
    "# get_session_history(789)\n",
    "get_session_history(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Olá! Estou funcionando bem, obrigado! E você? Como está seu dia?', response_metadata={'token_usage': {'completion_tokens': 21, 'prompt_tokens': 40, 'total_tokens': 61, 'completion_time': 0.028, 'prompt_time': 0.00994316, 'queue_time': 0.060754477999999994, 'total_time': 0.03794316}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_9cb648b966', 'finish_reason': 'stop', 'logprobs': None}, id='run-af2a7bfb-dbd5-40dd-816e-5571ac3199c2-0', usage_metadata={'input_tokens': 40, 'output_tokens': 21, 'total_tokens': 61})"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "with_message_history = RunnableWithMessageHistory(\n",
    "\tmodel,\n",
    "\tget_session_history,\n",
    ")\n",
    "\n",
    "with_message_history.invoke(\n",
    "\t[HumanMessage(content=\"ola, como vai?\")],\n",
    "\tconfig={\"configurable\": {\"session_id\": 1}},\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def send_message(model_name, message, session_id):\n",
    "\n",
    "    model = find_model(model_name)\n",
    "\n",
    "\n",
    "    return \n",
    "\n",
    "send_message(message=\"ei, como vai?\", model_name=\"llama-3.1-8b-instant\", session_id=78979)\n",
    "# if __name__ == \"main\":\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
